#!/usr/bin/env python3
'''
Provides multiple reusable helper functions.
'''

import functools
import itertools
import json
import logging
import logging.config
import os
import re
import time
from itertools import chain, combinations
from typing import Callable, Dict, List, Tuple

import bs4
import pydot

from . import model, constants


def boundVars(rule: str) -> List[str]:
    '''
    Returns a list of unique bound variables, including `This`, for a given
    (partial) rule, but excluding `null`.

    The input `'p(This, Par1) :- node(This), next(This, Next), p(null, '` yields
    `['Next', 'Par1', 'This']`.
    '''
    vars_ = re.findall(r'[A-Z]\w+', rule)
    return sorted(list(set(vars_)))


def relevantEPname(rule, memoryGraph: model):
    head, _ = rule.split(constants.DELIMITER_RULE)
    params = head.split("(")[1].split(")")[0].split(", ")
    pos = [a for (a, b) in enumerate(params) if b == "This"]
    assert len(pos) >= 1
    mypos = pos[0]
    return [ep["name"] for ep in memoryGraph.entrypoints()][mypos]


def logger():
    '''
    Returns an initialized logger object.
    '''
    conf_file = f'{getModuleFolder()}/{constants.LOGGING_CONFIG}'
    logging.config.fileConfig(
        conf_file,
        disable_existing_loggers=False
    )
    return logging.getLogger()


def getModuleFolder():
    '''
    Yields an absolute path to the `shape` folder without a trailing `/` in the
    end.
    '''
    return os.path.dirname(os.path.realpath(__file__))


def timer(func: Callable) -> Callable:
    """
    Provides an `@timer` function decorator to measure the execution times of a
    function. Prints the runtime of a function decorated with `@timer`.

    Adapted from https://realpython.com/primer-on-python-decorators
    """

    @functools.wraps(func)
    def wrapper_timer(*args, **kwargs):
        start_time = time.perf_counter()
        value = func(*args, **kwargs)
        end_time = time.perf_counter()
        run_time = end_time - start_time
        logger().debug(f'Finished {func.__name__!r} in {run_time:.2f} secs')
        return value

    return wrapper_timer


def pointstograph_to_JSON(data) -> Dict:
    '''
    Transforms points-to graphs (DOT format) captured using the *DSI: Data
    Structure Investigator* tool to JSON format.

    While entry pointers are explicitly mentioned in the output of DSI, it is
    often preferred to pick exactly one among the multiple existing entry
    pointers for a shape learnence. By default, the "longest running" node is
    selected. By construction of DSI, the longest running entry pointer/node is
    the one with the smallest id. However, this heuristics is problematic if
    *a)* the heap consists of two separate parts, where an entry pointer should
    be assigned to each part, and *b)* if the longest running entry pointer does
    properly indicate the beginning of a data structure, i.e., an element within
    a list rather than the first element of that list.

    Converts a points-to graph (PTG) generated by the DSI tool from DOT format
    to JSON format.
    '''
    # NOTE: The points-to graphs generated by DSI are not compliant with the DOT
    # standard. This function patches the content of such a DOT file and makes
    # it standard compliant.
    data = data.replace(r'label = <', r'label=<')

    graphs = pydot.graph_from_dot_data(data)

    # the final output comprises the following chunks of data
    vertices: List = []
    structs: List = []
    entrypoints: List = []

    # temporary dict to store a mapping from DOT ports to struct field names
    port2fieldname: Dict = {}

    assert len(graphs) == 1
    graph = graphs[0]
    graph: pydot.Dot = graph
    subgraphs = [
        sg for sg in graph.get_subgraphs()
        if sg.get_name() == "connected_vertices"
    ]
    assert len(subgraphs) == 1
    subgraph: pydot.Subgraph = subgraphs[0]

    # reconstruct struct information and vertices excluding assignment information
    for node in subgraph.get_nodes():
        node: pydot.Node = node

        html = bs4.BeautifulSoup(node.get("label")[1:][:-1], features="lxml")

        table_data = [
            [cell.text.split(", ") for cell in row("td")]
            for row in html("tr")
        ]

        # the NULL and UNDEF node can be ignored
        if table_data[2][0][0] in ["NULL", "UNDEF"]:
            continue

        struct_name = table_data[2][1][0].replace("struct ", "")

        # ignore the duplicate void * pointers caused by the CIL instrumentation
        # also ignore any other pointers
        if struct_name.endswith(" *"):
            continue

        field_types = [
            x[1][0]
            for x in table_data[3:-1]
            if x[0][0] != "compiler padding"
        ]
        field_names = [
            x[0][0]
            for x in table_data[3:-1]
            if x[0][0] != "compiler padding"
        ]
        type_name = list(zip(field_types, field_names))

        # only keep pointer fields, e.g., drop integers
        type_name = [x for x in type_name if x[0].endswith("*")]

        # reconstruct the struct definition if we have not done so far
        if struct_name not in [x["name"] for x in structs]:
            structs.append(
                {
                    "name": struct_name,
                    "fields": [
                        {
                            "type": typex,
                            "name": namex
                        }
                        for (typex, namex) in type_name
                    ]
                }
            )

        # adding vertex entry
        vertices.append(
            {
                "id": table_data[0][0][0],
                "struct": "struct %s" % struct_name,
                "assignment": [
                    {
                        "type": field["type"],
                        "name": field["name"],
                        "value": None
                    }
                    for field in [x["fields"] for x in structs if x["name"] == struct_name][0]
                ]
            }
        )

        # updating port2fieldname dict
        refindall = re.findall(
            r"in\">(\w+)(?:.*?)port=\"(\d+)out\"></td></tr>",
            str(html)
        )
        for fieldname, port in refindall:
            port2fieldname[port] = fieldname

    # reconstrucing assignment information, i.e., the edges of the graph
    for x in graph.get_edges():
        x: pydot.Edge = x

        node_source_id = re.match(
            r"\"\d+\"\:", x.get_source()
        ).group()[1:][:-2]

        # ignore edges from entry points
        if node_source_id not in [v["id"] for v in vertices]:
            continue

        node_source_port = re.findall(
            r"\"(\d+)out:e\"", x.get_source()
        )[0]

        field = port2fieldname[node_source_port]

        node_destination_id = re.match(
            r"\"\d+\"\:", x.get_destination()
        ).group()[1:][:-2]

        # DSI encodes the NULL value as a node with id 1 and apparently
        # sometimes with a 0 ...
        if node_destination_id in ["0", "1"]:
            value = "NULL"
        else:
            value = str(node_destination_id)

        # update the value information in the assignment of the node
        my_vertex = [
            v for v in vertices
            if v["id"] == node_source_id
        ][0]
        my_assignment = [
            a for a in my_vertex["assignment"]
            if a["name"] == field
        ][0]
        my_assignment["value"] = value

    # sort the vertices wrt to their id
    vertices.sort(key=lambda x: int(x["id"]))

    # NOTE: the ep selection should be made more sophisticated. One should
    # inspect `headout` edges, which resemble entry pointers and conduct a field
    # reachability analysis.

    # the node with the smallest id is picked as the ep (=entry point).
    entrypoints = [{
        "name": "ep",
        "type": vertices[0]["struct"],
        "target": vertices[0]["id"],
    }]

    # DSI encodes vertices with a fixed unique ID. However, this toolchain
    # assumes the ID to be a string. Hence, each vertex ID is prepended with the
    # letter `n`
    for vertex in vertices:
        vertex["id"] = f'n{vertex["id"]}'
        for assignment in vertex["assignment"]:
            if assignment["value"] != "NULL":
                assignment["value"] = f'n{assignment["value"]}'
    for entrypoint in entrypoints:
        if entrypoint["target"] != "NULL":
            entrypoint["target"] = f'n{entrypoint["target"]}'

    # The tool chain requires lower-case field names.
    for vertex in vertices:
        for assignment in vertex["assignment"]:
            assignment["name"] = assignment["name"].lower()
    for struct in structs:
        for field in struct["fields"]:
            field["name"] = field["name"].lower()

    # remove `struct` keyword in types as we consider just pointers
    for entrypoint in entrypoints:
        entrypoint["type"] = entrypoint["type"].replace("struct ", "")
    for struct in structs:
        for field in struct["fields"]:
            field["type"] = field["type"].replace("struct ", "")
            field["type"] = field["type"].replace(" *", "")
    for vertex in vertices:
        vertex["struct"] = vertex["struct"].replace("struct ", "")
        for assignment in vertex["assignment"]:
            assignment["type"] = assignment["type"].replace("struct ", "")
            assignment["type"] = assignment["type"].replace(" *", "")

    # assemble the final JSON dictionary
    dct = {
        "structs": structs,
        "vertices": vertices,
        "entrypoints": entrypoints
    }
    return json.dumps(dct, sort_keys=True)


class ShaPEexception(Exception):
    '''
    Raised if an exceptional situation is encountered during a computation.
    '''

    def __init__(self, value: str) -> None:
        self.value = value

    def __str__(self) -> str:
        return repr(self.value)


class Unique:
    '''
    A singleton class serving as a unique number generator throughout the
    overall execution of the script.

    ..note::
        The following code snippet depicts how this class is used to retrieve
        two unique values:

            i1: int = Unique().Integer()
            i2: int = Unique().Integer()
            assert i1 != i2

    Technically, attribute requests via `__getattr__` are delegated to an
    underlying hidden class.

    '''

    class __Unique:
        def __init__(self):
            '''
            Create a new counter instance using `itertools`.
            '''
            self.counter = itertools.count()

        def Integer(self) -> int:
            '''
            Yield the next integer.
            '''
            return next(self.counter)

    _instance: __Unique = None

    def __init__(self) -> None:
        '''
        Only create a new instance when no instance has been setup so far.
        '''
        if not Unique._instance:
            Unique._instance = Unique.__Unique()

    def reset(self) -> None:
        """
        Resets the counter, hence, use with care!
        """
        Unique._instance = None

    def __getattr__(self, name: str) -> Callable:
        return getattr(self._instance, name)


def parseRulesTemplate(
        templatePath: str
) -> List[str]:
    """
    Parses a rules template file and returns a list of the contained rules.
    Ignores empty lines and single line comments.
    """
    with open(templatePath, r'r') as target:
        rules = target.read().splitlines()
    rules = [r for r in rules if not r.startswith(r"%")]
    rules = [r for r in rules if not ''.__eq__(r.strip())]
    return rules


def prependClause(
        rule,
        clause
):
    """
    Prepends a clause to the beginning of a rule's tail.
    """
    (head, tail) = rule.split(constants.DELIMITER_RULE)
    return f'{head} :- {clause}, {tail}'


def multireplace(
        text: str,
        changes: List[Tuple[str, str]]
) -> str:
    """
    Performs a recursive independent multi-replace on the parameter `text`. The
    parameter `changes` is a list of tuples, where each tuple contains the
    original string as first element and the new string as second element. An
    independent replace is required if the list of changes cannot be computed
    sequentially due to contained  contradictions.

    For example, consider the case where `A` should become `B` and `B` should
    become `C` is applied to the string `AB`. A sequential computation of
    replace yields `CC`, however, `BC` is desired. When supplied with `AB` as
    `text` and `[('A', 'B'), ('B', 'C')]` as `changes` yields `BC` as output.

    Note: the code is adapted from
    https://codereview.stackexchange.com/questions/64096
    """
    if not changes:
        return text

    from_, to = changes[0]
    parts = text.split(from_)
    return to.join((multireplace(part, changes[1:]) for part in parts))


def extractFieldNames(
        rules: List[str]
) -> List[str]:
    """
    Extracts field names from a list of rules using.

    The rule `p(This) :- node(This), fieldA(This, null), fieldB(This, This),
    fieldC(This, FieldC), fieldD(This, FieldD), true.` yields `['fieldA',
    'fieldB', 'fieldC', 'fieldD']` as output.
    """
    fields = []
    for rule in rules:
        _, tail = rule.split(constants.DELIMITER_RULE)
        rule_fields = re.findall(constants.RE_FIELDNAMES, tail)
        assert rule_fields
        if not fields:
            fields = rule_fields
        else:
            assert fields == rule_fields
    assert fields
    return fields


def homogeneously_typed(
    memory_graphs
) -> None:
    """
    Checks if a list of memory graphs is homogeneously typed, i.e., they all contain nodes of the same single struct.

    :param memory_graphs: The input memory graphs.
    :raises ShaPEexception: If the memory graphs are not homogeneously typed.
    :return: None
    """
    if not memory_graphs:
        return
    structs = memory_graphs[0].structs()
    if len(structs) != 1:
        raise ShaPEexception("The memory graph is not homogeneously typed.")
    for memory_graph in memory_graphs:
        if memory_graph.structs() != structs:
            raise ShaPEexception(
                "The memory graph is not homogeneously typed.")


def same_entrypointer_names(
    memory_graphs
) -> None:
    # check that all memory graphs contain the same entry pointers
    if memory_graphs:
        ep_names = [e["name"] for e in memory_graphs[0].entrypoints()]
    for memory_graph in memory_graphs:
        if ep_names != [e["name"] for e in memory_graph.entrypoints()]:
            raise ShaPEexception(
                "The input memory graphs do not contain the same entrypointers."
            )


def powerset(iterable):
    "powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"
    s = list(iterable)
    ch = chain.from_iterable(combinations(s, r) for r in range(len(s)+1))
    return list(ch)
